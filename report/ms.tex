\documentclass[11pt]{article}
\usepackage{amsmath,textcomp,amssymb,geometry,graphicx}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}}\text{ }}
\begin{document}
\title{Fast, Robust Classification with Applications to Periodic Variable Stars}
\author{Siqi Wu, Mark Rogers, and James Long}
\maketitle


\section{Introduction}

\section{The Data}
\subsection{Background on Periodic Variables}
Modern astronomical surveys observe millions of light sources over the course of a mission lasting a few years. Periodic variables, sources which vary periodically in brightness over time, are some of the most interesting. In the 1920's, periodic variables were crucial in Edwin Hubble's discovery the existence of galaxies \cite{berendzen1971hubble}. More recently, periodic variables have played an important role in determining expansion of the universe \cite{freedman2010hubble}.

Periodic variables may be divided into a few dozen classes based on physical properties of light sources. Separating the sources into classes is a critical step in turning raw astronomical observations into scientific knowledge. The size of modern data sets requires that much of this work be automated by machine learning and statistical classifiers. 

Figure \ref{fig:cepheid} displays the light curve (i.e. time series) of a periodic variable belonging to the class Classical Cepheid. The points in plot a) represent flux measurements in magnitudes (i.e. brightness of the source) made by the telescope at particular times. The 0 point on the time axis is arbitrary. Using fourier methods, one can estimate a period from the measurements in plot a).  Plot b) of Figure \ref{fig:cepheid} displays the flux measurements of the same object. However here the x-axis is phase of each time measurement, computed using the estimated period of 4.51 days. Here we can observe the structure of the periodic variation. This is known as the \textit{folded light curve}.
\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{2000.pdf}
      \caption{Light curve of a Classical type variable star.\label{fig:cepheid}}
    \end{includegraphics}
  \end{center}
\end{figure}

Figure \ref{fig:mira} displays an example of a Mira light curve. From the y-axis we can see that this source has higher amplitude than the Classical Cepheid (this is typical of the Mira class) and more sinusoidal variation (also typical). Note that the fourier methods appear to have estimated an incorrect period for this source. The true period appears to be around 161 days, half of the estimate.
\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{204.pdf}
      \caption{Light curve of a Mira type variable star.\label{fig:mira}}
    \end{includegraphics}
  \end{center}
\end{figure}
\subsection{Classification Methodology}
There has been a lot of recent progress in the astronomy literature towards developing highly accurate classifiers for periodic variables \cite{debosscher2007automated,richards2011machine,dubath2011random}. The standard approach works as follows. A telescope observes a source $j$ at times $t_{1},\ldots,t_{l}$, recording flux measurements of $m_{1},\ldots,m_{l}$. Typically there are measures of uncertainty on the flux measurements $e_{1},\ldots,e_{l}$. So each source $j$ is initially characterized by an $l \times 3$ matrix $D_j=\{(t_{i},m_{i},e_{i})\}_{i=1}^{l}$. Note that $l$, the number of times the source is observed, is different for each $D_j$. Also the time sampling of the flux measurements is irregular and different for each source. Associated with each source is a classification, such as Mira, Classical Cepheid, RR Lyrae, etc.

In order to construct a classifier, features are \textit{extracted} from $D$ (i.e. take functions of $D$) that will separate sources into different classes. Features vary from study to study, but typical ones include period (inverse of strongest fourier frequency), amplitude, skew, and estimates of derivatives.

If we compute $p$ features and have a total of $n$ training stars of known class ($D_1, \ldots D_n$), then we can use standard classification techniques on this $n\times p$ data matrix to construct a classifier. Given this classifier, we can then assign a class to a new source by extracting features and running the features through the classifier.


\subsection{Uncertain Features}
A major problem with the standard approach is the high levels and heteroskedastic nature of the uncertainty in the features due to having poorly sampled time series ($l$ is small) or high error in the flux measurements ($e_{i}$ are systematically large). This leads to situations where features meant to represent physical quantities of the time series, such as amplitude or period, are incorrect. As an example \textbf{TODO: Include example with nice graphic here}

\section{Light Curves}

Figures \ref{fig:mira}, \ref{fig:cepheid}, \ref{fig:rrlyrae} show the light curves (i.e. time series) of three stars. Each is of a different class. The figures show the raw light curve (time on x-axis, magnitude on y-axis) and folded light curve (phase on x-axis, magnitude on y-axis). The phase is determined by computing a period (sometimes wrong!, for example figure \ref{fig:mira}) for each star, and then looking at the remainder of time divided by the period. The folded light curve often make the structure of the function much clearer.





\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{4000.pdf}
      \caption{Light curve of a RR Lyrae AB variable star.\label{fig:rrlyrae}}
    \end{includegraphics}
  \end{center}
\end{figure}



\section{Initial Classification Work}

\subsection{Ignoring Errors}
I made a data set of 5508 of these light curves of class Mira, Classical Cepheid, and RR Lyrae AB. Random forest (a type of classifier) obtained a 0.55\% error rate, without using any feature error information. So the current classes may be too easy. I could generate features for some stars that belong to classes that are more similar to each other e.g. using stars from classes RR Lyrae C and RR Lyrae D (not used here) are a lot alike and would have much higher error rates.

\subsection{Generating Hyper-rectangles}
To generate the hyper-rectangles I did the following:
\begin{enumerate}
\item sliced each light curve into 5 contiguous parts. ordering measurements in time: slice 1 is 0\% through 50\%, slice 2 is 10\% through 60\%, . . .
\item derive features for each of these parts
\item put the interval minimum at the lowest value of the feature for the 5 slices. put the interval max at the maximum feature value across the 5 slices
\end{enumerate}
There are several problems with this approach.
\begin{enumerate}
\item measurements in the middle of the light curve get used more often
\item sometimes the intervals do not contain the feature obtained when using the whole light curve. this is because taking shorter sections of light curves biases certain features high or low (frequency significance features tend to go down, should probably just get rid of these anyway)
\end{enumerate}
Bootstrap sampling might be a good approach, but this would destroy cadence sensitive features. So not sure what to do. This might be something interesting to discuss in the paper: \textbf{Determining feature error intervals for time series / image data is difficult.}



\section{Notes on ``Robust Classification with Interval Data''}
\begin{enumerate}
\item how is new data point classified? this doesn't seem to be mentioned anywhere
\item role of $\rho$ is not super clear. described as a ``global measure of uncertainty'' on page 3 but then is then is optimized over e.g. equation 16
\item $\Sigma$ known and given
\item no mention of kernels for SVM with intervals. (kernels are mentioned with respect to MPM on page 11) perhaps SVM intervals don't work with intervals. that seems really bad. maybe if kernel preserves rectangular structure of interval?
\end{enumerate}
\section{Note on Data}
\begin{enumerate}
\item for shorter lightcurves, certain features are biased downwards (for example freq\_signif features). probably std as well. should do bootstrap sampling instead? but bootstrap sampling destroys p2p features.
\end{enumerate}


\bibliographystyle{plain}
\bibliography{refs}



\end{document}
