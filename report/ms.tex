\documentclass[11pt]{article}
\usepackage{amsmath,textcomp,amssymb,geometry,graphicx}
\newcommand{\argmin}[1]{\underset{#1}{\operatorname{argmin}}\text{ }}
\begin{document}
\title{Fast, Robust Classification with Applications to Periodic Variable Stars}
\author{Siqi Wu, Mark Rogers, and James Long}
\maketitle


\section{Introduction}

\section{The Data}
\subsection{Background on Periodic Variables}
Modern astronomical surveys observe millions of light sources (stars, galaxies, asteroids) over the course of a mission lasting a few years. Periodic variables, sources which vary periodically in brightness over time, are some of the most interesting. In the 1920's, periodic variables were crucial in Edwin Hubble's discovery the existence of galaxies \cite{berendzen1971hubble}. More recently, periodic variables have played an important role in determining expansion of the universe \cite{freedman2010hubble}.

Periodic variables may be divided into a few dozen classes based on physical properties of light sources. Separating the sources into classes is a critical step in turning raw astronomical observations into scientific knowledge. The size of modern data sets requires that much of this work be automated by machine learning and statistical classifiers. 
\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{2000.pdf}
      \caption{Light curve of a Classical Cepheid type variable star. The brightness of the star is on the y-axis. For the top plot the brightness is plotted against time. This time series is periodic. Using fourier methods we can estimate a period of 4.51 days. We can convert the times from the top plot into phase ((time modulo period) / period)). Brightness versus phase is plotted in the bottom plot. Here we can observe the structure in the time series, which is usually similar for stars of the same class but different for stars of different classes.\label{fig:cepheid}}
    \end{includegraphics}
  \end{center}
\end{figure}

Figure \ref{fig:cepheid} displays the light curve (i.e. time series) of a periodic variable belonging to the class Classical Cepheid. The points in the top plot represent flux measurements in magnitudes (i.e. brightness of the source) made by the telescope at particular times. The 0 point on the time axis is arbitrary. Using fourier methods, one can estimate a period using these measurements.  The lower plot of Figure \ref{fig:cepheid} displays the flux measurements of the same object. However here the x-axis is phase of each time measurement, computed using the estimated period of 4.51 days. Here we can observe the structure of the periodic variation. This is known as the \textit{folded light curve}.

Figure \ref{fig:mira} displays an example of a Mira light curve. From the y-axis we can see that this source has higher amplitude than the Classical Cepheid (this is typical of the Mira class) and more sinusoidal variation (also typical). Note that the fourier methods appear to have estimated an incorrect period for this source. The true period appears to be around 161 days, half of the estimate.
\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{204.pdf}
      \caption{Light curve of a Mira type variable star.\label{fig:mira}}
    \end{includegraphics}
  \end{center}
\end{figure}
\subsection{Classification Methodology}
There has been a lot of recent progress in the astronomy literature towards developing highly accurate classifiers for periodic variables \cite{debosscher2007automated,richards2011machine,dubath2011random}. The standard approach works as follows. A telescope observes a source $j$ at times $t_{1},\ldots,t_{l}$, recording flux measurements of $m_{1},\ldots,m_{l}$. Typically there are measurements of uncertainty on the flux measurements $e_{1},\ldots,e_{l}$. So each source $j$ is initially characterized by an $l \times 3$ matrix $D_j=\{(t_{i},m_{i},e_{i})\}_{i=1}^{l}$. Note that $l$, the number of times the source is observed, is different for each $D_j$. Also the time sampling of the flux measurements is irregular and different for each source. Associated with each source is a classification, such as Mira, Classical Cepheid, RR Lyrae, etc.

In order to construct a classifier, features are \textit{extracted} from $D_j$ (i.e. take functions of $D_j$) that will separate sources into different classes. Features vary from study to study, but typical ones include period (inverse of strongest fourier frequency), amplitude, skew, and estimates of derivatives.

If we compute $p$ features and have a total of $n$ training stars of known class ($D_1, \ldots D_n$), then we can use standard classification techniques on this $n\times p$ data matrix to construct a classifier. Given this classifier, we can then assign a class to a new source by extracting features and running the features through the classifier.


\subsection{Uncertain Features}
\begin{figure}[h]
  \begin{center}
    \begin{includegraphics}[scale=.5]{period_amplitude.pdf}
      \caption{Period-Amplitude relationship for two classes: \textit{Classical Cepheid} stars and \textit{Population II Cepheid} stars. The green box represents (roughly) the physically possible range of periods and amplitudes. Clearly some of these features have been estimated incorrectly.\label{fig:period_amplitude}}
    \end{includegraphics}
  \end{center}
\end{figure}
A major problem with the standard approach is the high levels and heteroskedastic nature of the uncertainty in the features due to having poorly sampled time series ($l$ is small), high error in the flux measurements ($e_{i}$ are systematically large), or irregular nature of sampling ($t_i$'s are highly concentrated, giving a poor representation of variation). This leads to situations where features meant to represent physical quantities of the time series, such as amplitude or period, are incorrect. As an example in Figure \ref{fig:period_amplitude} we plot the period and amplitude features for two classes of stars with a box around known physical limits for these features for these two classes. Some of the observations have values outside these physical limits, clearly indicating that the features are incorrectly estimated. This suggests that classifiers which incorporate feature uncertainty may be able to acheive improved performance.

%% Many of the features used for classification rely on a correct estimate of period for the object. For example, features related to the derivative are often computed based on the folded light curve. If the light curve is folded on the wrong period, then the derivative estimates are likely to be wrong.

\section{SVMs for Interval Data}
Support Vector Machines (SVMs) are a popular method for constructing classifiers. Let $x_i \in \mathbb{R}^p$ be the vector of features for observation $i$ and $y_i$ its class (either $-1$ or $+1$), we can determine the SVM classifier by solving the optimization problem,
\begin{equation}
\label{eq:svm}
\min_{\beta,\beta_0}  \sum_{i=1}^n (1 - y_i(\beta^Tx + \beta_0))_{+} + \frac{\lambda}{2}\beta^T\beta
\end{equation}
The optimal $\beta^*$ and $\beta_0^*$ are used to classify a new observation $x$ using $sign(\beta^* x + \beta_0)$. $\lambda$ is a tuning parameter that balances a tradeoff between maximizing the margin and separating observations in different classes. An optimal $\lambda$ may be chosen using 0-1 loss on a test set or through cross-validation. See \cite{scholkopf2002learning} for an extensive overview of SVMs.

Various extensions to the standard SVM have been proposed that seek to incorporate uncertainty in the features into the optimization problem. These formulations often take (or can be interpreted) as minimizing the objective function for a worst case allocation of features in some fixed set, i.e.
\begin{equation}
\label{eq:svm_minimax}
\min_{\beta,\beta_0}  \max_{z \in \mathcal{X}} \sum_{i=1}^n (1 - y_i(\beta^Tz_i + \beta_0))_{+} + \frac{\lambda}{2}\beta^T\beta
\end{equation}
See \cite{bhattacharyya2004robust,shivaswamy2006second,ben2011chance} for discussions of some of these models.



TO DISCUSS:
\begin{enumerate}
\item similarities to elastic net of LASSO / SVM e.g. Wang \cite{wang2007hybrid}
\item our algorithm is not contained (?) in those considered by Russet \cite{rosset2007piecewise}
\end{enumerate}


\section{Path Algorithm for Interval SVM}

\section{Application to Variable Star Data Sets}
\subsection{Constructing the Intervals from the Time Series}
In certain applications, methods for constructing hyper-rectangles (or hyper-spheres) in feature space may be fairly straitforward. For example in El Ghaoui \cite{el2003robust}, the authors discuss applications to micro-array data where several replicates of some experiment are available, and a hyper-rectangle can be chosen to enclose all replicates.

With astronomy data there is no clearly correct way to construct intervals around features. A few possibilities include:
\begin{enumerate}
\item Make width of feature interval proportional to number of measurements in time series. Long time series will have small intervals around features, short time series will have wide intervals. For simple features, such as the standard deviation of the brightness measurements, making the interval width go down at rate root-n has a probabilistic interpretation via the central limit theorem.
\item Subsample the time series and derive features for each subsample. Represent observations as hyper-rectangles that contain features derived from every subsample (or a certain fraction of the subsamples).
\item Heuristically put intervals around observations with features that are wrong. For example, the amplitude of a star cannot be greater than 6 magnitudes, so any star with amplitude greater than 6 mags could be given an interval that contains values less than 6.
\end{enumerate}
In this work we take the second approach. While the first approach is attractive for simple features, many features (such as frequency) do not have a sqrt-n convergence to the true value. Further the irregular time sampling means that even simple features may not have a root-n convergence. The third approach involves a lot of domain knowledge and will change from application to application. Further, there is no guarantee that features within the range of what is physically possible are actually correct.

Figure \ref{fig:interval_construction} describes precisely how we subsample the time series and determine interval widths. The details of this procedure could be changed. For example one could bootstrap sample the time measurements, instead of subsampling contiguous sections. Certain computational considerations enter here. It takes around 1 second to derive features for an average length light curve. So sampling, say 20 times, could become prohibitively expansive if the data set is initially at the limits of what is computationally feasible.
\begin{figure*}[ht]
\begin{center}
{\small
\framebox[6in]{
\begin{minipage}[t]{5.8in}
% Insert here your text
\begin{center} \textbf{Constructing Hyper-rectangles from Time Series} \end{center}
\begin{enumerate}
\item Order the light curve measurements in time i.e. $\{(t_1,m_1,e_1),(t_2,m_2,e_2), \ldots , (t_l,m_l,e_l)\}$ where $t_i < t_j$ for $i < j$.
\item Slice each light curve into 5 contiguous sections, producing 5 time series. Slice 1 is $(t_i,m_i,e_i)$ for $\frac{0}{10}l \leq i \leq \frac{5}{10}l$, slice 2 is $\frac{1}{10}l \leq i \leq \frac{6}{10}l$, ect.
%% \begin{enumerate}
%% \item $\{(t_1,m_1,e_1), \ldots , (t_{l/2},m_{l/2},e_{l/2})\}$
%% \item $\{(t_1,m_1,e_1),(t_2,m_2,e_2), \ldots , (t_l,m_l,e_l)\}$
%% \end{enumerate}
\item Derive features for each of these slices.
\item Put the interval minimum at the lowest value of the feature for the 5 slices. Put the interval max at the maximum feature value across the 5 slices.
\end{enumerate}
\end{minipage}
}
}
\end{center}
\caption{Description of interval construction algorithm.\label{fig:interval_construction}}
\label{lb}
\end{figure*}

%% \begin{enumerate}
%% \item measurements in the middle of the light curve get used more often
%% \item sometimes the intervals do not contain the feature obtained when using the whole light curve. this is because taking shorter sections of light curves biases certain features high or low (frequency significance features tend to go down, should probably just get rid of these anyway)
%% \end{enumerate}
%% Bootstrap sampling might be a good approach, but this would destroy cadence sensitive features. So not sure what to do. This might be something interesting to discuss in the paper: \textbf{Determining feature error intervals for time series / image data is difficult.}




%% \section{Light Curves}

%% Figures \ref{fig:mira}, \ref{fig:cepheid}, \ref{fig:rrlyrae} show the light curves (i.e. time series) of three stars. Each is of a different class. The figures show the raw light curve (time on x-axis, magnitude on y-axis) and folded light curve (phase on x-axis, magnitude on y-axis). The phase is determined by computing a period (sometimes wrong!, for example figure \ref{fig:mira}) for each star, and then looking at the remainder of time divided by the period. The folded light curve often make the structure of the function much clearer.


%% \begin{figure}[h]
%%   \begin{center}
%%     \begin{includegraphics}[scale=.5]{4000.pdf}
%%       \caption{Light curve of a RR Lyrae AB variable star.\label{fig:rrlyrae}}
%%     \end{includegraphics}
%%   \end{center}
%% \end{figure}



%% \section{Initial Classification Work}

%% \subsection{Ignoring Errors}
%% I made a data set of 5508 of these light curves of class Mira, Classical Cepheid, and RR Lyrae AB. Random forest (a type of classifier) obtained a 0.55\% error rate, without using any feature error information. So the current classes may be too easy. I could generate features for some stars that belong to classes that are more similar to each other e.g. using stars from classes RR Lyrae C and RR Lyrae D (not used here) are a lot alike and would have much higher error rates.


\subsection{The Data Sets}
The first dataset analyzed contained two classes of Cepheids (CEP):  classical and [popII].  Each class consisted of $n=200$ observations and $p=58$ features so that each observation is hyperrectangle in $\mathbb{R}^{58}$. The second dataset consisted of two classes of RR,  RR Lyrae AB and RR Lyrae D, with the same values of $n$ and $p$.
\subsubsection{Preprocessing the data with quantile ranking}
A quantile ranking technique was used to normalize values in each feature dimension by reducing the effects of outliers. Viewing the interval data as a three-dimensional array, the end-slices corresponding to the lower- and upper-bounds of the confidence intervals were isolated and then concatenated together to yield a $2n\times p$ array whose values were then mapped to the standard normal distribution. Features containing all zeroes or some NaNs were removed from the dataset.

\subsection{Results}

\subsubsection{Performance}
The performance of the combined SVM model was compared to those of its degenerates by computing expected losses for multiple values of $\lambda$ and $\rho$.  For a given $(\lambda,\rho)$, the expected loss was computed by performing cross-validation in 90-10 splits so that the union of testing points across splits is the entire dataset and the intersection is disjoint. See surface plots of loss versus $(\lambda,\rho)$: for the CEP dataset, $\lambda\in \lbrace 0\rbrace\cup [0.375,9]$ and $\rho\in\lbrace 0\rbrace\cup [0.90,0.32]$ while for the RR dataset, $\lambda\in\lbrace 0\rbrace\cup [54,284]$ and $\rho\in[0.00,0.48]$. Observe that $(\lambda^*,\rho^*)\neq (0,0)$ for both datasets, which implies that the combined model outperforms both of its degenerates. For the CEP dataset, the optimal $(\lambda^*,\rho^*)=(9,0.320)$ yielded 13.25\% classification error while for the RR dataset, $(\lambda^*,\rho^*)=(284,0.48)$ yielded 21.50\% classification error. THESE NUMBERS DON'T LOOK RIGHT, MUST RERUN analyze_feature.m.

The curves of loss versus $\lambda$ and loss versus $\rho$ were also analyzed.  The loss versus $\lambda$ plot corresponds to the standard point SVM model in Hastie while the loss versus $\rho$ plot corresponds to the interval SVM model in El Ghaoui. Observe the convex-like curvatures, which suggest global minima and hence optimal $\lambda$ and $\rho$. 

\subsubsection{Feature selection as suggested by $||\beta||_0$ values}



\subsection{Conclusions}
\begin{enumerate}
\item constructing intervals is non-trivial in many high dimensional problems
\item not clear that this robust framework is ideal when new observation might have low error on certain features
\item kernels, are they possible to use
\item links to code / git repo
\end{enumerate}

\bibliographystyle{plain}
\bibliography{refs}



\end{document}
